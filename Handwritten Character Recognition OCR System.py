# -*- coding: utf-8 -*-
"""Assignment Writer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XKILtOT6lnr-QY_LGUfDaCc7Bnc1QwDp

Setting Up the Environment and Dataset
"""

# Install required packages
!pip install -q kaggle tensorflow matplotlib seaborn scikit-learn opencv-python

# Import necessary libraries
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam
import cv2
from google.colab import files
import zipfile
import warnings
warnings.filterwarnings('ignore')

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

print("TensorFlow version:", tf.__version__)
print("GPU Available:", tf.config.list_physical_devices('GPU'))

"""Kaggle Dataset Setup"""

# Upload your kaggle.json file
!rm -rf ~/.kaggle
!rm -r kaggle.json
!rm -r kaggle\ \(1\).json
!rm -r kaggle\ \(2\).json
print("Please upload your kaggle.json file:")
files.upload()

# Set up Kaggle API credentials
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Remove any existing files first
!rm -rf "English Handwritten Characters Dataset"
!rm -f english-handwritten-characters-dataset.zip

# Then download again
!kaggle datasets download -d dhruvildave/english-handwritten-characters-dataset
!unzip -o -q english-handwritten-characters-dataset.zip

# Check the dataset structure
!ls -la

"""Data Exploration and Understanding"""

import re

# Updated data exploration for filename-based labels
dataset_path = '/content/Img'

# Get all image files
image_files = [f for f in os.listdir(dataset_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
print(f"Total image files found: {len(image_files)}")

# Analyze filename patterns to extract character labels
def extract_label_from_filename(filename):
    """Extract character label from filename"""
    match = re.search(r'img(\d+)-', filename)
    if match:
        return int(match.group(1))
    return None

def number_to_character(num):
    """Convert number to character based on standard encoding"""
    if 1 <= num <= 10:
        return str(num - 1)  # Digits 0-9
    elif 11 <= num <= 36:
        return chr(ord('A') + num - 11)  # A-Z
    elif 37 <= num <= 62:
        return chr(ord('a') + num - 37)  # a-z
    else:
        return f"unknown_{num}"

# Test the mapping with sample files
sample_labels = {}
for filename in image_files[:10]:
    label_num = extract_label_from_filename(filename)
    char_label = number_to_character(label_num) if label_num else None
    sample_labels[filename] = char_label

print(f"\nSample filename to character mapping:")
for filename, char in sample_labels.items():
    print(f"{filename} -> '{char}'")

"""Optional: Debug Section"""

# DEBUG: Check filename pattern extraction
print("=== DEBUGGING FILENAME EXTRACTION ===")
sample_files = image_files[:5]
for filename in sample_files:
    label_num = extract_label_from_filename(filename)
    char_label = number_to_character(label_num) if label_num else None
    print(f"{filename} -> num: {label_num} -> char: '{char_label}'")

# Check number range in your dataset
all_nums = []
for filename in image_files[:100]:  # Check first 100 files
    label_num = extract_label_from_filename(filename)
    if label_num is not None:
        all_nums.append(label_num)

if all_nums:
    print(f"Number range in dataset: {min(all_nums)} to {max(all_nums)}")
    print(f"Unique numbers found: {sorted(set(all_nums))[:20]}...")
else:
    print("ERROR: No valid numbers extracted from filenames")

"""Data Visualization"""

# Visualize sample images from each class
def visualize_samples_from_files(dataset_path, image_files, samples_per_class=1):
    """Visualize sample images from filename-based dataset"""

    # Group files by character label
    char_groups = {}
    for filename in image_files:
        label_num = extract_label_from_filename(filename)
        char_label = number_to_character(label_num) if label_num else None

        if char_label is not None:  # Only check for None, not 'unknown'
            if char_label not in char_groups:
                char_groups[char_label] = []
            char_groups[char_label].append(filename)

    # Debug output
    print(f"Total character groups found: {len(char_groups)}")
    print(f"Sample characters: {list(char_groups.keys())[:10]}")

    # Sort characters for display
    sorted_chars = sorted(char_groups.keys())

    # Create visualization
    fig, axes = plt.subplots(8, 8, figsize=(16, 16))
    fig.suptitle('Sample Handwritten Characters', fontsize=16)

    for idx, char in enumerate(sorted_chars[:64]):  # Show first 64 characters
        row = idx // 8
        col = idx % 8

        if char_groups[char]:
            # Load and display the first image for this character
            img_path = os.path.join(dataset_path, char_groups[char][0])
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

            axes[row, col].imshow(img, cmap='gray')
            axes[row, col].set_title(f"'{char}'", fontsize=10)
            axes[row, col].axis('off')

    plt.tight_layout()
    plt.show()

    # Print character distribution
    char_counts = {char: len(files) for char, files in char_groups.items()}
    print(f"\nCharacter distribution:")
    for char in sorted(char_counts.keys())[:10]:
        print(f"'{char}': {char_counts[char]} images")

    return char_groups # Return char_groups

# Call the function and get char_groups
char_groups = visualize_samples_from_files(dataset_path, image_files)

# Plot distribution of images per class - ERROR-SAFE VERSION
char_counts = {char: len(files) for char, files in char_groups.items()}

if char_counts:  # Check if dictionary is not empty
    plt.figure(figsize=(15, 6))
    classes = list(char_counts.keys())
    counts = list(char_counts.values())

    if len(classes) > 0 and len(counts) > 0:
        plt.bar(range(len(classes)), counts)
        plt.title('Distribution of Images per Character Class')
        plt.xlabel('Character Classes')
        plt.ylabel('Number of Images')

        # Safe x-tick labeling
        step = max(1, len(classes) // 10)  # Show ~10 labels max
        plt.xticks(range(0, len(classes), step),
                  [classes[i] for i in range(0, len(classes), step)],
                  rotation=45)

        plt.tight_layout()
        plt.show()

        print(f"Average images per class: {np.mean(counts):.2f}")
        print(f"Min images per class: {np.min(counts)}")
        print(f"Max images per class: {np.max(counts)}")
    else:
        print("ERROR: No valid character data found")
else:
    print("ERROR: char_counts dictionary is empty")

"""Data Loading and Preprocessing"""

def load_and_preprocess_data_from_files(dataset_path, img_size=(64, 64)):
    """Load and preprocess images when labels are in filenames"""
    images = []
    labels = []

    # Get all image files
    image_files = [f for f in os.listdir(dataset_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    print(f"Loading {len(image_files)} images...")

    for img_file in image_files:
        # Extract label from filename
        label_num = extract_label_from_filename(img_file)

        if label_num is not None:
            # Convert number to character
            char_label = number_to_character(label_num)

            # Skip unknown labels
            if char_label.startswith('unknown'):
                continue

            # Load and preprocess image
            img_path = os.path.join(dataset_path, img_file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

            if img is not None:
                # Resize image
                img_resized = cv2.resize(img, img_size)

                # Normalize pixel values to [0, 1]
                img_normalized = img_resized.astype(np.float32) / 255.0

                # Add to lists
                images.append(img_normalized)
                labels.append(char_label)

    return np.array(images), np.array(labels)

# Load the data with updated function
print("Loading dataset with filename-based labels...")
X, y = load_and_preprocess_data_from_files(dataset_path)

print(f"Images shape: {X.shape}")
print(f"Labels shape: {y.shape}")

# Check label distribution
unique_labels, counts = np.unique(y, return_counts=True)
print(f"\nNumber of unique characters: {len(unique_labels)}")
print(f"Sample characters: {unique_labels[:10]}")

# Reshape images to add channel dimension (for CNN)
X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)
print(f"Images shape after reshape: {X.shape}")

# Encode labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
num_classes = len(label_encoder.classes_)

print(f"Number of classes: {num_classes}")
print(f"Class labels: {label_encoder.classes_[:10]}...")  # Show first 10 classes

"""Data Splitting and Augmentation"""

# Split the data
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded
)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 * 0.85 â‰ˆ 0.15
)

print(f"Training set: {X_train.shape[0]} samples")
print(f"Validation set: {X_val.shape[0]} samples")
print(f"Test set: {X_test.shape[0]} samples")

# Convert labels to categorical
y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes)
y_val_cat = tf.keras.utils.to_categorical(y_val, num_classes)
y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes)

# Data augmentation
train_datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=False,  # Don't flip characters horizontally
    fill_mode='nearest'
)

# Validation data generator (no augmentation)
val_datagen = ImageDataGenerator()

# Create data generators
batch_size = 32
train_generator = train_datagen.flow(X_train, y_train_cat, batch_size=batch_size)
val_generator = val_datagen.flow(X_val, y_val_cat, batch_size=batch_size)

"""Model Architecture"""

def create_advanced_cnn_model(input_shape, num_classes):
    """
    Create an advanced CNN model for character recognition
    """
    model = models.Sequential([
        # First Convolutional Block
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),

        # Second Convolutional Block
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),

        # Third Convolutional Block
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),

        # Fourth Convolutional Block
        layers.Conv2D(256, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.25),

        # Global Average Pooling instead of Flatten to reduce parameters
        layers.GlobalAveragePooling2D(),

        # Dense layers
        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),

        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),

        # Output layer
        layers.Dense(num_classes, activation='softmax')
    ])

    return model

# Create the model
input_shape = (64, 64, 1)
model = create_advanced_cnn_model(input_shape, num_classes)

# Compile the model
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Display model summary
model.summary()

# Plot model architecture
tf.keras.utils.plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)

"""Training Setup with Callbacks"""

# Create callbacks
callbacks_list = [
    # Early stopping
    callbacks.EarlyStopping(
        monitor='val_accuracy',
        patience=10,
        restore_best_weights=True,
        verbose=1
    ),

    # Reduce learning rate on plateau
    callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    ),

    # Model checkpoint
    callbacks.ModelCheckpoint(
        'best_ocr_model.h5',
        monitor='val_accuracy',
        save_best_only=True,
        save_weights_only=False,
        verbose=1
    ),

    # CSV logger
    callbacks.CSVLogger('training_log.csv')
]

# Calculate steps per epoch
steps_per_epoch = len(X_train) // batch_size
validation_steps = len(X_val) // batch_size

print(f"Steps per epoch: {steps_per_epoch}")
print(f"Validation steps: {validation_steps}")

"""Model Training"""

# Train the model
print("Starting model training...")
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=50,  # We'll use early stopping, so this is the maximum
    validation_data=val_generator,
    validation_steps=validation_steps,
    callbacks=callbacks_list,
    verbose=1
)

print("Training completed!")

"""Training Visualization"""

def plot_training_history(history):
    """
    Plot training history
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    # Plot training & validation accuracy
    ax1.plot(history.history['accuracy'], label='Training Accuracy')
    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax1.set_title('Model Accuracy')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy')
    ax1.legend()
    ax1.grid(True)

    # Plot training & validation loss
    ax2.plot(history.history['loss'], label='Training Loss')
    ax2.plot(history.history['val_loss'], label='Validation Loss')
    ax2.set_title('Model Loss')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Loss')
    ax2.legend()
    ax2.grid(True)

    plt.tight_layout()
    plt.show()

    # Print final metrics
    final_train_acc = history.history['accuracy'][-1]
    final_val_acc = history.history['val_accuracy'][-1]
    final_train_loss = history.history['loss'][-1]
    final_val_loss = history.history['val_loss'][-1]

    print(f"Final Training Accuracy: {final_train_acc:.4f}")
    print(f"Final Validation Accuracy: {final_val_acc:.4f}")
    print(f"Final Training Loss: {final_train_loss:.4f}")
    print(f"Final Validation Loss: {final_val_loss:.4f}")

plot_training_history(history)

"""Model Evaluation"""

# Load the best model
best_model = tf.keras.models.load_model('best_ocr_model.h5')

# Evaluate on test set
print("Evaluating model on test set...")
test_loss, test_accuracy = best_model.evaluate(X_test, y_test_cat, verbose=0)
print(f"Test Accuracy: {test_accuracy:.4f}")
print(f"Test Loss: {test_loss:.4f}")

# Make predictions
y_pred = best_model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# SELECT BEST EXAMPLES FOR DEMO TABLE
print("\n=== Generating Demo Table Data ===")

# Find high-confidence correct predictions
correct_predictions = []
for i in range(len(y_test)):
    confidence = np.max(y_pred[i])  # Use already computed predictions
    pred_class = y_pred_classes[i]

    if pred_class == y_test[i] and confidence > 0.85:  # High confidence + correct
        char_label = label_encoder.classes_[y_test[i]]
        correct_predictions.append((i, confidence, char_label))

# Sort by confidence and pick top examples
correct_predictions.sort(key=lambda x: x[1], reverse=True)

# Select diverse character types for demo
demo_examples = []
selected_chars = set()

# Try to get one example from each category
categories = {
    'digit': [str(i) for i in range(10)],
    'uppercase': [chr(i) for i in range(ord('A'), ord('Z')+1)],
    'lowercase': [chr(i) for i in range(ord('a'), ord('z')+1)]
}

for idx, confidence, char in correct_predictions:
    if len(demo_examples) >= 5:  # Limit to 5 examples
        break

    # Check if we need this character type
    char_category = None
    if char in categories['digit']:
        char_category = 'digit'
    elif char in categories['uppercase']:
        char_category = 'uppercase'
    elif char in categories['lowercase']:
        char_category = 'lowercase'

    if char not in selected_chars:
        demo_examples.append({
            'index': idx,
            'character': char,
            'confidence': confidence * 100,
            'category': char_category
        })
        selected_chars.add(char)

# Print demo table data
print("\nDemo Table Data for README:")
print("| Input Description | Predicted Character | Confidence |")
print("|------------------|-------------------|------------|")

for example in demo_examples:
    char = example['character']
    conf = example['confidence']
    category = example['category']

    if category == 'digit':
        desc = f"Handwritten number {char}"
    elif category == 'uppercase':
        desc = f"Handwritten letter {char}"
    else:
        desc = f"Handwritten letter {char}"

    print(f"| {desc} | **{char}** | {conf:.1f}% |")

# Save demo images
print(f"\nSaving {len(demo_examples)} demo images...")
import os
os.makedirs('demo', exist_ok=True)

for i, example in enumerate(demo_examples):
    idx = example['index']
    char = example['character']
    img = X_test[idx].squeeze()

    plt.figure(figsize=(3, 3))
    plt.imshow(img, cmap='gray')
    plt.title(f"Character: {char} (Confidence: {example['confidence']:.1f}%)")
    plt.axis('off')
    plt.savefig(f'demo/sample_{char}.png', bbox_inches='tight', dpi=150, facecolor='white')
    plt.close()

print("Demo data generation completed!")
print("Demo images saved in 'demo/' folder")

# Classification report
class_names = label_encoder.classes_
print("\nClassification Report:")
print(classification_report(y_test, y_pred_classes, target_names=class_names))

# Confusion Matrix
def plot_confusion_matrix(y_true, y_pred, class_names, figsize=(20, 16)):
    """
    Plot confusion matrix
    """
    cm = confusion_matrix(y_true, y_pred)

    plt.figure(figsize=figsize)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    return cm

# Plot confusion matrix (this might be large due to 62 classes)
cm = plot_confusion_matrix(y_test, y_pred_classes, class_names)

# Calculate per-class accuracy
class_accuracy = cm.diagonal() / cm.sum(axis=1)
class_acc_df = pd.DataFrame({
    'Class': class_names,
    'Accuracy': class_accuracy
}).sort_values('Accuracy')

print("\nPer-class Accuracy (Bottom 10):")
print(class_acc_df.head(10))
print("\nPer-class Accuracy (Top 10):")
print(class_acc_df.tail(10))

"""Prediction Visualization"""

def visualize_predictions(model, X_test, y_test, y_pred_classes, label_encoder, num_samples=20):
    """
    Visualize model predictions
    """
    # Select random samples
    indices = np.random.choice(len(X_test), num_samples, replace=False)

    fig, axes = plt.subplots(4, 5, figsize=(15, 12))
    fig.suptitle('Model Predictions on Test Samples', fontsize=16)

    for i, idx in enumerate(indices):
        row = i // 5
        col = i % 5

        # Get image and predictions
        img = X_test[idx].squeeze()
        true_label = label_encoder.classes_[y_test[idx]]
        pred_label = label_encoder.classes_[y_pred_classes[idx]]
        confidence = np.max(y_pred[idx])

        # Plot image
        axes[row, col].imshow(img, cmap='gray')

        # Set title with prediction info
        color = 'green' if true_label == pred_label else 'red'
        axes[row, col].set_title(f'True: {true_label}\nPred: {pred_label}\nConf: {confidence:.3f}',
                                color=color, fontsize=10)
        axes[row, col].axis('off')

    plt.tight_layout()
    plt.show()

# Visualize predictions
visualize_predictions(best_model, X_test, y_test, y_pred_classes, label_encoder)

"""Inference Function"""

def preprocess_image_for_prediction(image_path, target_size=(64, 64)):
    """
    Preprocess a single image for prediction
    """
    # Load image in grayscale
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    if img is None:
        raise ValueError(f"Could not load image from {image_path}")

    # Resize image
    img_resized = cv2.resize(img, target_size)

    # Normalize pixel values
    img_normalized = img_resized.astype(np.float32) / 255.0

    # Add batch and channel dimensions
    img_batch = np.expand_dims(np.expand_dims(img_normalized, axis=-1), axis=0)

    return img_batch, img_resized

def predict_character(model, image_path, label_encoder, top_k=3):
    """
    Predict character from an image file
    """
    try:
        # Preprocess image
        img_batch, img_display = preprocess_image_for_prediction(image_path)

        # Make prediction
        predictions = model.predict(img_batch, verbose=0)

        # Get top-k predictions
        top_indices = np.argsort(predictions[0])[-top_k:][::-1]
        top_probs = predictions[0][top_indices]
        top_classes = [label_encoder.classes_[i] for i in top_indices]

        # Display results
        plt.figure(figsize=(10, 4))

        # Show image
        plt.subplot(1, 2, 1)
        plt.imshow(img_display, cmap='gray')
        plt.title('Input Image')
        plt.axis('off')

        # Show predictions
        plt.subplot(1, 2, 2)
        y_pos = np.arange(len(top_classes))
        plt.barh(y_pos, top_probs)
        plt.yticks(y_pos, top_classes)
        plt.xlabel('Confidence')
        plt.title(f'Top {top_k} Predictions')
        plt.gca().invert_yaxis()

        plt.tight_layout()
        plt.show()

        return top_classes[0], top_probs[0]

    except Exception as e:
        print(f"Error during prediction: {str(e)}")
        return None, None

# Example usage (you can test this with any image)
print("Inference function created successfully!")
print("To use it, call: predict_character(best_model, 'path_to_image.jpg', label_encoder)")

"""Model Saving and Export"""

# Save the model in different formats
print("Saving model...")

# Save as .h5 format
best_model.save('best_ocr_model.h5')

# Save as .keras format (recommended modern format)
best_model.save('handwritten_character_ocr_model.keras')

# Save label encoder
import pickle
with open('label_encoder.pkl', 'wb') as f:
    pickle.dump(label_encoder, f)

print("Model saved successfully!")

# Create a summary report
summary_report = f"""
# Handwritten Character Recognition OCR Model - Summary Report

## Dataset Information:
- Total Images: {len(X)}
- Number of Classes: {num_classes}
- Image Size: 64x64 pixels (grayscale)
- Classes: Digits (0-9), Uppercase (A-Z), Lowercase (a-z)

## Model Architecture:
- Type: Deep Convolutional Neural Network
- Total Parameters: {model.count_params():,}
- Input Shape: {input_shape}
- Output Classes: {num_classes}

## Training Configuration:
- Train/Validation/Test Split: 70%/15%/15%
- Batch Size: {batch_size}
- Data Augmentation: Yes (rotation, shift, shear, zoom)
- Optimizer: Adam (initial lr=0.001)
- Loss Function: Categorical Crossentropy

## Performance Metrics:
- Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)
- Test Loss: {test_loss:.4f}
- Training Epochs: {len(history.history['accuracy'])}

## Files Generated:
- best_ocr_model.h5 (Best model during training)
- handwritten_character_ocr_model.keras (Final model - modern format)
- label_encoder.pkl (Label encoder for inference)
- training_log.csv (Training history)

## Usage:
The model can recognize handwritten characters with high accuracy.
Use the predict_character() function for inference on new images.
"""

print(summary_report)

# Save the summary report
with open('model_summary_report.txt', 'w') as f:
    f.write(summary_report)

print("\nProject completed successfully!")
print("All files have been saved and the OCR system is ready for use.")